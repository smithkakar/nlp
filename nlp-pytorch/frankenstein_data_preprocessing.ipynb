{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ranging-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from argparse import Namespace\n",
    "import collections\n",
    "import nltk.data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coordinate-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    raw_data='data/books/frankenstein.txt',\n",
    "    window_size=5,\n",
    "    train_prop=0.7,\n",
    "    val_prop=0.15,\n",
    "    test_prop=0.15,\n",
    "    processed_data='data/books/frankeinstein_processed_data.csv',\n",
    "    seed=1337\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loaded-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "with open(args.raw_data) as fp:\n",
    "    book = fp.read()\n",
    "sentences = tokenizer.tokenize(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "peripheral-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3427 sentences\n",
      "Sample:  No incidents have hitherto befallen us that would make a figure in a\n",
      "letter.\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences), \"sentences\")\n",
    "print(\"Sample: \", sentences[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blind-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(' '))\n",
    "    text = re.sub(r'([.,!?])', r' \\1 ', text)\n",
    "    text = re.sub(r'[^a-zA-Z.,!?]+', r' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "convertible-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentences = [preprocess_text(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "steady-country",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no incidents have hitherto befallen us that would make a figure in a letter . '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "focal-intention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I arrived here yesterday, and my first task is to assure\\nmy dear sister of my welfare and increasing confidence in the success\\nof my undertaking.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "automated-forwarding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i arrived here yesterday , and my first task is to assure my dear sister of my welfare and increasing confidence in the success of my undertaking . '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "french-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_TOKEN = '<MASK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hollow-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smithkakar/.conda/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc2053372c04ceaaa98b27bd5c38635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create windows\n",
    "flatten = lambda outer_list: [item for inner_list in outer_list for item in inner_list]\n",
    "windows = flatten([list(nltk.ngrams([MASK_TOKEN] * args.window_size + sentence.split(' ') + \\\n",
    "                 [MASK_TOKEN] * args.window_size, args.window_size * 2 + 1)) \\\n",
    "                  for sentence in tqdm_notebook(cleaned_sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expressed-mystery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frankenstein , or the modern prometheus by mary wollstonecraft godwin shelley letter st . petersburgh , dec . th , to mrs . saville , england you will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such evil forebodings . '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lesser-desktop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<MASK>',\n",
       " '<MASK>',\n",
       " '<MASK>',\n",
       " '<MASK>',\n",
       " '<MASK>',\n",
       " 'frankenstein',\n",
       " ',',\n",
       " 'or',\n",
       " 'the',\n",
       " 'modern',\n",
       " 'prometheus')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "color-diploma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('frankenstein',\n",
       " ',',\n",
       " 'or',\n",
       " 'the',\n",
       " 'modern',\n",
       " 'prometheus',\n",
       " 'by',\n",
       " 'mary',\n",
       " 'wollstonecraft',\n",
       " 'godwin',\n",
       " 'shelley')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "modern-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smithkakar/.conda/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15977c5e372462fbf21eb765a1f0c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for window in tqdm_notebook(windows):\n",
    "    target_token = window[args.window_size]\n",
    "    context = []\n",
    "    # everything excluding center word or mask token are the context words\n",
    "    for i, token in enumerate(window):\n",
    "        if token == MASK_TOKEN or i == args.window_size:\n",
    "            continue\n",
    "        else:\n",
    "            context.append(token)\n",
    "    data.append([' '.join(token for token in context), target_token])\n",
    "    \n",
    "cbow_data = pd.DataFrame(data, columns=['context', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vocational-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(cbow_data)\n",
    "def get_split(row_num):\n",
    "    if row_num <= n*args.train_prop:\n",
    "        return 'train'\n",
    "    elif (row_num > n*args.train_prop) and (row_num <= n*args.train_prop + n*args.val_prop):\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'test'\n",
    "cbow_data['split'] = cbow_data.apply(lambda row: get_split(row.name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "theoretical-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, or the modern prometheus</td>\n",
       "      <td>frankenstein</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frankenstein or the modern prometheus by</td>\n",
       "      <td>,</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frankenstein , the modern prometheus by mary</td>\n",
       "      <td>or</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frankenstein , or modern prometheus by mary wo...</td>\n",
       "      <td>the</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frankenstein , or the prometheus by mary wolls...</td>\n",
       "      <td>modern</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context        target  split\n",
       "0                         , or the modern prometheus  frankenstein  train\n",
       "1           frankenstein or the modern prometheus by             ,  train\n",
       "2       frankenstein , the modern prometheus by mary            or  train\n",
       "3  frankenstein , or modern prometheus by mary wo...           the  train\n",
       "4  frankenstein , or the prometheus by mary wolls...        modern  train"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "iraqi-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_data.to_csv(args.processed_data, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
